<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3D Face Model with Fixed Tracking</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            background: #000;
            overflow: hidden;
            font-family: Arial, sans-serif;
        }
        
        #container {
            display: flex;
            width: 100vw;
            height: 100vh;
            align-items: center;
            justify-content: center;
            position: relative;
            overflow: hidden;
        }
        
        #video {
            position: absolute;
            top: 0;
            left: 0;
            width: 100vw;
            height: 100vh;
            object-fit: cover;
            transform: scaleX(1);
        }
        
        #webglCanvas {
            position: absolute;
            top: 0;
            left: 0;
            width: 100vw;
            height: 100vh;
            pointer-events: none;
            object-fit: cover;
        }
        
        #status {
            position: absolute;
            top: 20px;
            left: 20px;
            z-index: 1000;
            color: white;
            background: rgba(0,0,0,0.9);
            padding: 15px 20px;
            border-radius: 10px;
            font-size: 14px;
            font-weight: bold;
            backdrop-filter: blur(10px);
            border: 2px solid rgba(255,255,255,0.1);
            max-width: 350px;
        }
        
        .status-item {
            margin: 5px 0;
        }
        
        #modelOptions {
            position: absolute;
            bottom: 20px;
            left: 20px;
            z-index: 1000;
            color: white;
            background: rgba(0,0,0,0.9);
            padding: 15px 20px;
            border-radius: 10px;
            font-size: 12px;
            backdrop-filter: blur(10px);
            border: 2px solid rgba(255,255,255,0.1);
        }
        
        button {
            background: #007acc;
            color: white;
            border: none;
            padding: 8px 12px;
            margin: 5px;
            border-radius: 5px;
            cursor: pointer;
            font-size: 12px;
        }
        
        button:hover {
            background: #005a9e;
        }
        
        @media (max-width: 768px) {
            #status, #modelOptions {
                font-size: 11px;
                padding: 10px 12px;
                max-width: calc(50vw - 20px);
            }
            
        }
    </style>
</head>
<body>
    <div id="container">
        <video id="video" autoplay muted playsinline></video>
        <canvas id="webglCanvas"></canvas>
        
        <div id="status">
            <div class="status-item">Status: <span id="statusText">Loading...</span></div>
            <div class="status-item">Model: <span id="modelStatus">Select Model Type</span></div>
            <div class="status-item">Face: <span id="faceDetected">No</span></div>
            <div class="status-item">Expressions: <span id="expressionCount">0</span></div>
            <div class="status-item">Sync: <span id="syncInfo">Ready</span></div>
        </div>
        
        <div id="modelOptions">
            <div><strong>Model Options:</strong></div>
            <button onclick="loadBuiltInModel()">Use Built-in Face Model</button>
            <button onclick="loadGLBModel()">Try GLB Model</button>
            <button onclick="loadFromURL()">Load from URL</button>
            <div style="margin-top: 10px;">
                <input type="file" id="fileInput" accept=".glb,.gltf" style="display:none;">
                <button onclick="document.getElementById('fileInput').click()">Upload GLB File</button>
            </div>
        </div>
        
    </div>

    <script type="importmap">
        {
            "imports": {
                "three": "https://unpkg.com/three@0.157.0/build/three.module.js",
                "three/addons/": "https://unpkg.com/three@0.157.0/examples/jsm/"
            }
        }
    </script>
    
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest"></script>
    <script src="https://unpkg.com/three@0.157.0/build/three.min.js"></script>
    
    <script type="module">
        import * as THREE from 'three';
        import { GLTFLoader } from 'three/addons/loaders/GLTFLoader.js';
        import { KTX2Loader } from 'three/addons/loaders/KTX2Loader.js';
        import { MeshoptDecoder } from 'three/addons/libs/meshopt_decoder.module.js';

        class ModernFaceTracker {
            constructor() {
                this.video = document.getElementById('video');
                this.webglCanvas = document.getElementById('webglCanvas');
                this.gltfLoader = new GLTFLoader();
                this.ktx2Loader = new KTX2Loader(); 
                
                // Face detection
                this.faceMesh = null;
                this.camera = null;
                this.isProcessing = false;
                this.faces = [];
                
                // Three.js setup
                this.scene = null;
                this.threeCamera = null;
                this.renderer = null;
                this.faceModel = null;
                this.faceMeshObject = null;
                
                // Expression tracking
                this.expressions = {};
                this.morphTargetNames = [];
                this.expressionValues = {};
                
                // Face tracking - improved variables
                this.faceCenter = { x: 0.5, y: 0.5, z: 0 };
                this.headRotation = { x: 0, y: 0, z: 0 };
                this.faceScale = 1.0;
                this.videoAspect = 1;
                this.canvasAspect = 1;
                
                // REAL-WORLD FACE SIZE CALIBRATION
                this.AVERAGE_INTERPUPILLARY_DISTANCE = 0.063; // 63mm in meters - average human IPD
                this.AVERAGE_FACE_WIDTH = 0.14; // 140mm in meters - average human face width
                this.CAMERA_FOV_RADIANS = (50 * Math.PI) / 180; // Convert FOV to radians
                this.realWorldFaceScale = 1.0;
                
                // Smoothing factor
                this.smoothingFactor = 0.3;
                this.smoothedExpressions = {};
                this.smoothedPosition = { x: 0, y: 0, z: 0 };
                this.smoothedRotation = { x: 0, y: 0, z: 0 };
                this.smoothedScale = 1.0;

                this.baselineScale = null;
                
                // SINGLE MODEL MANAGEMENT
                this.currentPivotGroup = null; // Track current pivot group
                // this.modelUpdateCounter = 0;   // Prevent rapid updates
                this.lastModelUpdate = 0;      // Timestamp of last update
                // this.MODEL_UPDATE_INTERVAL = 16; // Minimum ms between updates (60fps)

                // FACE LOCK SYSTEM
                this.faceLockInitialized = false;
                this.faceLockCenter = { x: 0.5, y: 0.5, z: 0 };
                this.framesSinceLastFace = 0;
                this.maxFramesWithoutFace = 30; // Reset lock after 30 frames without face
                
                this.init();
            }
            
            async init() {
                try {
                    document.getElementById('statusText').textContent = 'Initializing...';
                    
                    await this.setupCamera();
                    await this.setupThreeJS();
                    await this.setupFaceDetection();
                    
                    this.startTracking();
                    this.setupResizeHandler();
                    this.setupFileHandler();
                    
                    document.getElementById('statusText').textContent = 'Ready - Select Model';
                    
                } catch (error) {
                    console.error('Initialization failed:', error);
                    document.getElementById('statusText').textContent = 'Error: ' + error.message;
                }
            }
            
            async setupCamera() {
                const configs = [
                    { video: { facingMode: 'user', width: { ideal: 1280 }, height: { ideal: 720 } } },
                    { video: { facingMode: 'user', width: { ideal: 640 }, height: { ideal: 480 } } },
                    { video: { facingMode: 'user' } }
                ];

                for (const config of configs) {
                    try {
                        const stream = await navigator.mediaDevices.getUserMedia(config);
                        this.video.srcObject = stream;
                        
                        await new Promise((resolve, reject) => {
                            this.video.onloadedmetadata = () => {
                                this.videoAspect = this.video.videoWidth / this.video.videoHeight;
                                resolve();
                            };
                            this.video.onerror = reject;
                            setTimeout(() => reject(new Error('Video timeout')), 10000);
                        });
                        
                        await this.video.play();
                        console.log('Camera setup successful');
                        return;
                        
                    } catch (error) {
                        console.warn('Camera config failed:', error);
                    }
                }
                
                throw new Error('Camera setup failed');
            }
            
            async setupThreeJS() {
                this.scene = new THREE.Scene();
                
                this.threeCamera = new THREE.PerspectiveCamera(
                    50, // FOV that matches typical face tracking
                    window.innerWidth / window.innerHeight,
                    0.1,
                    10
                );
                this.threeCamera.position.set(0, 0, 3); // Fixed camera position for stable face lock
                
                this.renderer = new THREE.WebGLRenderer({
                    canvas: this.webglCanvas,
                    alpha: true,
                    antialias: true
                });
                
                this.renderer.setSize(window.innerWidth, window.innerHeight);
                this.renderer.setClearColor(0x000000, 0);
                
                // Enable advanced blending for better face integration
                this.renderer.sortObjects = false;
                this.renderer.autoClear = false;
                
                // Enhanced lighting for better face integration
                const ambientLight = new THREE.AmbientLight(0xffffff, 0.6);
                this.scene.add(ambientLight);
                
                const keyLight = new THREE.DirectionalLight(0xffffff, 0.8);
                keyLight.position.set(0, 0, 2);
                keyLight.castShadow = false;
                this.scene.add(keyLight);
                
                const fillLight = new THREE.DirectionalLight(0xffffff, 0.3);
                fillLight.position.set(-1, 0, 1);
                this.scene.add(fillLight);
                
                const rimLight = new THREE.DirectionalLight(0xffffff, 0.2);
                rimLight.position.set(1, 0, -1);
                this.scene.add(rimLight);
                
                // CREATE BLENDING LAYER for better face integration
                this.createBlendingLayer();
                
                this.ktx2Loader.setTranscoderPath('https://unpkg.com/three@0.157.0/examples/jsm/libs/basis/');
                this.ktx2Loader.detectSupport(this.renderer);
                this.gltfLoader.setKTX2Loader(this.ktx2Loader);
                this.gltfLoader.setMeshoptDecoder(MeshoptDecoder);
                
                console.log('Three.js setup complete with blending layer');
            }
            
            // IMPROVED: Better blending layer for seamless face integration
            createBlendingLayer() {
                // Create a face-shaped mask that matches the main model better
                const blendGeometry = new THREE.SphereGeometry(0.16, 32, 32); // Slightly larger than main model
                blendGeometry.scale(0.85, 0.95, 0.65); // Match face proportions
                
                // Enhanced blending material
                const blendMaterial = new THREE.MeshLambertMaterial({
                    color: 0xFFDBB5, // Match skin tone
                    transparent: true,
                    opacity: 0.2, // Subtle but visible
                    blending: THREE.MultiplyBlending, // Better blending mode
                    depthWrite: false, // Don't interfere with main model
                    depthTest: true,
                    side: THREE.DoubleSide
                });
                
                this.blendingLayer = new THREE.Mesh(blendGeometry, blendMaterial);
                this.blendingLayer.name = 'blendingLayer';
                this.blendingLayer.renderOrder = 0; // Render first
                
                console.log('Enhanced blending layer created');
            }
            
            createBuiltInFaceModel() {
                return new Promise((resolve) => {
                    const group = new THREE.Group();
                    
                    // FACE POSITIONING FIX: Larger base geometry for proper face coverage
                    const faceGeometry = new THREE.SphereGeometry(0.15, 32, 32); // Increased from 0.1
                    faceGeometry.scale(0.8, 0.9, 0.6); // Better proportions
                    
                    const morphTargetNames = [
                        'browInnerUp', 'browDown_L', 'browDown_R', 'browOuterUp_L', 'browOuterUp_R',
                        'eyeLookUp_L', 'eyeLookUp_R', 'eyeLookDown_L', 'eyeLookDown_R',
                        'eyeLookIn_L', 'eyeLookIn_R', 'eyeLookOut_L', 'eyeLookOut_R',
                        'eyeBlink_L', 'eyeBlink_R', 'eyeSquint_L', 'eyeSquint_R',
                        'eyeWide_L', 'eyeWide_R', 'cheekPuff', 'cheekSquint_L', 'cheekSquint_R',
                        'noseSneer_L', 'noseSneer_R', 'jawOpen', 'jawForward', 'jawLeft', 'jawRight',
                        'mouthFunnel', 'mouthPucker', 'mouthLeft', 'mouthRight',
                        'mouthRollUpper', 'mouthRollLower', 'mouthShrugUpper', 'mouthShrugLower',
                        'mouthClose', 'mouthSmile_L', 'mouthSmile_R', 'mouthFrown_L', 'mouthFrown_R',
                        'mouthDimple_L', 'mouthDimple_R', 'mouthUpperUp_L', 'mouthUpperUp_R',
                        'mouthLowerDown_L', 'mouthLowerDown_R', 'mouthPress_L', 'mouthPress_R',
                        'mouthStretch_L', 'mouthStretch_R', 'tongueOut'
                    ];
                    
                    faceGeometry.morphAttributes = {};
                    faceGeometry.morphAttributes.position = [];
                    
                    morphTargetNames.forEach((name, index) => {
                        const morphGeometry = faceGeometry.clone();
                        this.applyMorphDeformation(morphGeometry, name);
                        const morphAttribute = new THREE.Float32BufferAttribute(
                            morphGeometry.attributes.position.array, 3
                        );
                        faceGeometry.morphAttributes.position.push(morphAttribute);
                    });
                    
                    // ENHANCED: Better material for proper face integration
                    const faceMaterial = new THREE.MeshLambertMaterial({
                        color: 0xFFDBB5,
                        morphTargets: true,
                        transparent: true,
                        opacity: 0.9, // Less transparent for better visibility
                        blending: THREE.NormalBlending,
                        side: THREE.DoubleSide,
                        depthWrite: true,
                        depthTest: true
                    });
                    
                    const faceMesh = new THREE.Mesh(faceGeometry, faceMaterial);
                    faceMesh.renderOrder = 1;
                    
                    faceMesh.morphTargetDictionary = {};
                    morphTargetNames.forEach((name, index) => {
                        faceMesh.morphTargetDictionary[name] = index;
                    });
                    
                    faceMesh.morphTargetInfluences = new Array(morphTargetNames.length).fill(0);
                    
                    group.add(faceMesh);
                    
                    const gltf = {
                        scene: group,
                        scenes: [group]
                    };
                    
                    console.log('Created built-in model with', morphTargetNames.length, 'morph targets');
                    resolve(gltf);
                });
            }
            
            applyMorphDeformation(geometry, morphName) {
                const positions = geometry.attributes.position.array;
                const vertexCount = positions.length / 3;
                
                for (let i = 0; i < vertexCount; i++) {
                    const x = positions[i * 3];
                    const y = positions[i * 3 + 1];
                    const z = positions[i * 3 + 2];
                    
                    if (morphName.includes('eyeBlink')) {
                        if (y > 0.02 && y < 0.15 && Math.abs(x) < 0.2 && z > 0.2) {
                            positions[i * 3 + 1] *= 0.1;
                        }
                    } else if (morphName.includes('jawOpen')) {
                        if (y < -0.1 && z > 0.1) {
                            positions[i * 3 + 1] -= 0.08;
                        }
                    } else if (morphName.includes('mouthSmile')) {
                        if (y > -0.15 && y < 0.05 && Math.abs(x) < 0.15 && z > 0.3) {
                            positions[i * 3 + 1] += 0.04;
                            if (morphName.includes('_L') && x < 0) {
                                positions[i * 3] -= 0.03;
                            } else if (morphName.includes('_R') && x > 0) {
                                positions[i * 3] += 0.03;
                            }
                        }
                    } else if (morphName.includes('browInnerUp')) {
                        if (y > 0.2 && Math.abs(x) < 0.1 && z > 0.2) {
                            positions[i * 3 + 1] += 0.06;
                        }
                    } else if (morphName.includes('cheekPuff')) {
                        if (Math.abs(y) < 0.1 && Math.abs(x) > 0.08 && Math.abs(x) < 0.25 && z > 0.15) {
                            positions[i * 3 + 2] += 0.04;
                        }
                    }
                }
                
                geometry.attributes.position.needsUpdate = true;
            }
            
            async loadGLBModelModern(url) {
                return new Promise((resolve, reject) => {
                    document.getElementById('modelStatus').textContent = 'Loading GLB...';
                    
                    this.gltfLoader.load(
                        url,
                        (gltf) => {
                            console.log('GLB loaded:', gltf);
                            resolve(gltf);
                        },
                        (progress) => {
                            if (progress.total > 0) {
                                const percent = Math.round((progress.loaded / progress.total) * 100);
                                document.getElementById('modelStatus').textContent = `Loading GLB... ${percent}%`;
                            }
                        },
                        (error) => {
                            console.error('GLB loading failed:', error);
                            reject(error);
                        }
                    );
                });
            }
            
            setupFileHandler() {
                const fileInput = document.getElementById('fileInput');
                fileInput.addEventListener('change', async (event) => {
                    const file = event.target.files[0];
                    if (file) {
                        try {
                            const url = URL.createObjectURL(file);
                            const gltf = await this.loadGLBModelModern(url);
                            this.setupLoadedModel(gltf, 'Uploaded GLB');
                            URL.revokeObjectURL(url);
                        } catch (error) {
                            console.error('File upload failed:', error);
                            document.getElementById('modelStatus').textContent = 'Upload Failed ❌';
                        }
                    }
                });
            }

            destroyPersistentModel() {
                if (this.persistentPivotGroup) {
                    this.scene.remove(this.persistentPivotGroup);
                    this.persistentPivotGroup = null;
                }
                
                this.persistentFaceModel = null;
                this.persistentBlendingLayer = null;
                this.modelInitialized = false;
                
                console.log('Persistent model destroyed');
            }

            setupLoadedModel(gltf, modelType) {
                // Clean up existing persistent model
                this.destroyPersistentModel();
                
                this.faceModel = gltf.scene;
                
                let faceMeshFound = false;
                
                this.faceModel.traverse((child) => {
                    if (child.isMesh && child.morphTargetDictionary) {
                        this.faceMeshObject = child;
                        this.morphTargetNames = Object.keys(child.morphTargetDictionary);
                        faceMeshFound = true;
                        
                        child.material.morphTargets = true;
                        child.material.needsUpdate = true;
                        console.log('Found face mesh with morph targets:', this.morphTargetNames);
                    }
                });
                
                if (faceMeshFound) {
                    this.initializeExpressions();
                    document.getElementById('expressionCount').textContent = this.morphTargetNames.length;
                    document.getElementById('modelStatus').textContent = `${modelType} Loaded ✓`;
                    document.getElementById('modelStatus').style.color = '#4CAF50';
                    
                    // Initialize persistent model with new model
                    this.initializePersistentModel();
                } else {
                    document.getElementById('modelStatus').textContent = `${modelType} - No Morph Targets`;
                    document.getElementById('modelStatus').style.color = '#ff9800';
                }
                
                const box = new THREE.Box3().setFromObject(this.faceModel);
                const size = box.getSize(new THREE.Vector3());
                const baseScale = 0.4;
                this.faceModel.scale.setScalar(baseScale);
                
                console.log(`${modelType} setup complete with persistent model system`);
            }
            
            initializeExpressions() {
                this.morphTargetNames.forEach(name => {
                    this.expressions[name] = 0;
                    this.smoothedExpressions[name] = 0;
                });
            }

            async setupFaceDetection() {
                try {
                    const { FaceLandmarker, FilesetResolver } = await import('https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest');
                    
                    const filesetResolver = await FilesetResolver.forVisionTasks(
                        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
                    );

                    try {
                        this.faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                            baseOptions: {
                                modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task',
                                delegate: "GPU"
                            },
                            outputFaceBlendshapes: true,
                            outputFacialTransformationMatrixes: true,
                            runningMode: "VIDEO",
                            numFaces: 1
                        });
                    } catch (error) {
                        console.log("GPU failed, falling back to CPU");
                        this.faceLandmarker = await FaceLandmarker.createFromOptions(filesetResolver, {
                            baseOptions: {
                                modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task',
                                delegate: "CPU"
                            },
                            outputFaceBlendshapes: true,
                            outputFacialTransformationMatrixes: true,
                            runningMode: "VIDEO",
                            numFaces: 1
                        });
                    }
                    
                    console.log('Face Landmarker initialized for SINGLE FACE');
                    this.startVideoProcessing();
                    
                } catch (error) {
                    console.error('Face Landmarker initialization failed:', error);
                    throw new Error('Face Landmarker setup failed: ' + error.message);
                }
            }

            startVideoProcessing() {
                const processVideoFrame = () => {
                    if (this.video.readyState >= 2 && !this.isProcessing) {
                        this.processFrame();
                    }
                    requestAnimationFrame(processVideoFrame);
                };
                
                processVideoFrame();
                console.log('Video processing started');
            }

            async processFrame() {
                if (this.isProcessing || !this.faceLandmarker) return;
                
                this.isProcessing = true;
                try {
                    const startTimeMs = performance.now();
                    const results = await this.faceLandmarker.detectForVideo(this.video, startTimeMs);
                    this.onFaceResults(results);
                } catch (error) {
                    console.error('Face detection error:', error);
                } finally {
                    this.isProcessing = false;
                }
            }

            clearAllModels() {
                this.hidePersistentModel();
            }


            renderSingleFaceModel() {
                if (!this.faceModel || !this.renderer) return;
                
                // SINGLE MODEL MANAGEMENT: Remove existing model first
                this.clearAllModels();
                
                // Rate limiting check
                this.modelUpdateCounter++;
                if (this.modelUpdateCounter % 2 !== 0) {
                    return; // Skip every other frame for performance
                }
                
                // Create single pivot group
                const pivotGroup = new THREE.Group();
                pivotGroup.name = 'facePivot';
                pivotGroup.userData = { isMainModel: true }; // Mark as main model
                
                // Set pivot position to the face position
                const facePosition = this.convertToWorldCoords(this.smoothedPosition);
                pivotGroup.position.set(facePosition.x, facePosition.y, facePosition.z);
                
                // Apply rotations to the pivot group
                pivotGroup.rotation.set(
                    this.headRotation.x - Math.PI/4,
                    this.headRotation.y,
                    this.headRotation.z
                );
                
                // Clone and setup model
                const modelInstance = this.faceModel.clone();
                modelInstance.name = 'faceModel';
                modelInstance.position.set(0, 0, 0);
                
                const finalScale = Math.max(0.2, Math.min(0.7, this.smoothedScale));
                modelInstance.scale.setScalar(finalScale);
                
                // Add model to pivot
                pivotGroup.add(modelInstance);
                
                // Add blending layer if exists
                if (this.blendingLayer) {
                    const blendingInstance = this.blendingLayer.clone();
                    blendingInstance.name = 'blendingLayer';
                    blendingInstance.position.set(0, 0, 0);
                    blendingInstance.scale.setScalar(finalScale * 1.1);
                    pivotGroup.add(blendingInstance);
                }
                
                // Apply expressions
                if (this.faceMeshObject && this.morphTargetNames.length > 0) {
                    const faceMesh = this.findFaceMesh(modelInstance);
                    if (faceMesh && faceMesh.morphTargetInfluences) {
                        this.morphTargetNames.forEach((name, index) => {
                            if (this.smoothedExpressions[name] !== undefined) {
                                faceMesh.morphTargetInfluences[index] = this.smoothedExpressions[name];
                            }
                        });
                    }
                }
                
                // Store reference and add to scene
                this.currentPivotGroup = pivotGroup;
                this.scene.add(pivotGroup);
                
                // Render
                this.renderer.clear();
                this.renderer.render(this.scene, this.threeCamera);
                
                // Update sync info
                const activeExpressions = Object.values(this.smoothedExpressions).filter(v => v > 0.1).length;
                document.getElementById('syncInfo').textContent = 
                    `Scale: ${finalScale.toFixed(2)}, Active: ${activeExpressions}, Single Model`;
            }

            initializePersistentModel() {
                if (this.modelInitialized || !this.faceModel) return;
                
                console.log('Initializing persistent model...');
                
                // Create persistent pivot group
                this.persistentPivotGroup = new THREE.Group();
                this.persistentPivotGroup.name = 'persistentFacePivot';
                
                // Create persistent face model
                this.persistentFaceModel = this.faceModel.clone();
                this.persistentFaceModel.name = 'persistentFaceModel';
                this.persistentFaceModel.position.set(0, 0, 0);
                
                // Create persistent blending layer
                if (this.blendingLayer) {
                    this.persistentBlendingLayer = this.blendingLayer.clone();
                    this.persistentBlendingLayer.name = 'persistentBlendingLayer';
                    this.persistentBlendingLayer.position.set(0, 0, 0);
                    this.persistentPivotGroup.add(this.persistentBlendingLayer);
                }
                
                // Add model to pivot group
                this.persistentPivotGroup.add(this.persistentFaceModel);
                
                // Add to scene
                this.scene.add(this.persistentPivotGroup);
                
                // Mark as initialized
                this.modelInitialized = true;
                
                console.log('Persistent model created and added to scene');
            }

            updatePersistentModel() {
                if (this.isRendering) return; 
                
                if (!this.modelInitialized) {
                    this.initializePersistentModel();
                    if (!this.modelInitialized) return; 
                }
                
                this.isRendering = true;
                
                try {
                    // Update pivot position (face tracking)
                    const facePosition = this.convertToWorldCoords(this.smoothedPosition);
                    this.persistentPivotGroup.position.set(facePosition.x, facePosition.y, facePosition.z);
                    
                    // FIXED: Clear any existing rotations first
                    this.persistentPivotGroup.rotation.set(0, 0, 0);
                    
                    // FIXED: Apply pitch and yaw to the pivot group (for head turning)
                    this.persistentPivotGroup.rotation.set(
                        this.headRotation.x ,  // Pitch (head up/down)
                        this.headRotation.y,              // Yaw (head left/right)
                        0                                 // No roll on pivot group
                    );
                    
                    // FIXED: Apply roll (tilt) directly to the model for natural head tilt
                    this.persistentFaceModel.rotation.set(
                        0,                                // No additional pitch on model
                        0,                                // No additional yaw on model
                        this.headRotation.z               // Roll (head tilt) applied to model
                    );
                    
                    // Update scale
                    const finalScale = Math.max(0.2, Math.min(0.7, this.smoothedScale));
                    this.persistentFaceModel.scale.setScalar(finalScale);
                    
                    if (this.persistentBlendingLayer) {
                        this.persistentBlendingLayer.scale.setScalar(finalScale * 1.1);
                        // Apply same roll rotation to blending layer
                        this.persistentBlendingLayer.rotation.set(
                            0,                            // No pitch
                            0,                            // No yaw
                            this.headRotation.z           // Same roll as main model
                        );
                    }
                    
                    // Update morph target expressions (keep existing code)
                    if (this.faceMeshObject && this.morphTargetNames.length > 0) {
                        const faceMesh = this.findFaceMesh(this.persistentFaceModel);
                        if (faceMesh && faceMesh.morphTargetInfluences) {
                            this.morphTargetNames.forEach((name, index) => {
                                if (this.smoothedExpressions[name] !== undefined) {
                                    faceMesh.morphTargetInfluences[index] = this.smoothedExpressions[name];
                                }
                            });
                        }
                    }
                    
                    // Make sure model is visible
                    this.persistentPivotGroup.visible = true;
                    
                    // Render scene
                    this.renderer.clear();
                    this.renderer.render(this.scene, this.threeCamera);
                    
                    // Update sync info
                    const activeExpressions = Object.values(this.smoothedExpressions).filter(v => v > 0.1).length;
                    document.getElementById('syncInfo').textContent = 
                        `Scale: ${finalScale.toFixed(2)}, Active: ${activeExpressions}, Tilt: ${(this.headRotation.z * 180/Math.PI).toFixed(1)}°`;
                        
                } catch (error) {
                    console.error('Error updating persistent model:', error);
                } finally {
                    this.isRendering = false;
                }
            }

            
            hidePersistentModel() {
                if (this.persistentPivotGroup) {
                    this.persistentPivotGroup.visible = false;
                    
                    // Render to show the hidden state
                    if (this.renderer) {
                        this.renderer.clear();
                        this.renderer.render(this.scene, this.threeCamera);
                    }
                }
            }


            onFaceResults(results) {
                // FORCE SINGLE FACE: Only use the first detected face
                this.faces = results.faceLandmarks && results.faceLandmarks.length > 0 ? [results.faceLandmarks[0]] : [];
                this.faceBlendshapes = results.faceBlendshapes && results.faceBlendshapes.length > 0 ? [results.faceBlendshapes[0]] : [];
                
                // NEW: Extract transformation matrix for better head rotation
                this.facialTransformationMatrix = results.facialTransformationMatrixes && results.facialTransformationMatrixes.length > 0 ? results.facialTransformationMatrixes[0] : null;
                
                const faceDetected = this.faces.length > 0;
                document.getElementById('faceDetected').textContent = faceDetected ? 'Yes (1)' : 'No';
                document.getElementById('faceDetected').style.color = faceDetected ? '#4CAF50' : '#f44336';
                
                if (faceDetected && this.faceModel && this.faceMeshObject) {
                    if (!this.faceLockInitialized) {
                        this.initializeFaceLock();
                    }
                    
                    this.framesSinceLastFace = 0;
                    this.calculateExpressionsFromBlendshapes();
                    
                    // NEW: Use transformation matrix for head rotation if available
                    if (this.facialTransformationMatrix) {
                        this.updateHeadRotationFromMatrix();
                    } else {
                        this.updateFaceTrackingFromLandmarks(); // Fallback to your existing method
                    }
                    
                    this.updatePersistentModel();
                    this.updateExpressionDebug();
                } else {
                    this.framesSinceLastFace++;
                    if (this.framesSinceLastFace > this.maxFramesWithoutFace) {
                        this.faceLockInitialized = false;
                        this.hidePersistentModel();
                    }
                    document.getElementById('expressionValues').textContent = 'No face detected';
                }
            }

            updateExpressionDebug() {
                const activeExpressions = Object.entries(this.smoothedExpressions)
                    .filter(([name, value]) => value > 0.05)
                    .sort(([,a], [,b]) => b - a)
                    .slice(0, 15)
                    .map(([name, value]) => `${name}: ${value.toFixed(2)}`)
                    .join('<br>');
                
                const debugElement = document.getElementById('expressionValues');
                const rotationSource = this.facialTransformationMatrix ? 'Matrix' : 'Landmarks';
                
                if (activeExpressions) {
                    debugElement.innerHTML = activeExpressions + 
                        `<br><br><strong>Position:</strong><br>X: ${this.smoothedPosition.x.toFixed(3)}<br>Y: ${this.smoothedPosition.y.toFixed(3)}<br>Z: ${this.smoothedPosition.z.toFixed(3)}` +
                        `<br><br><strong>Rotation (${rotationSource}):</strong><br>Pitch: ${(this.headRotation.x * 180/Math.PI).toFixed(1)}°<br>Yaw: ${(this.headRotation.y * 180/Math.PI).toFixed(1)}°<br>Roll: ${(this.headRotation.z * 180/Math.PI).toFixed(1)}°` +
                        `<br><br><strong>Scale:</strong> ${this.smoothedScale.toFixed(2)}`;
                } else {
                    debugElement.innerHTML = 'No active expressions';
                }
            }


            updateHeadRotationFromMatrix() {
                if (!this.facialTransformationMatrix) return;
                
                // Create THREE.js Matrix4 from MediaPipe transformation matrix
                const matrix = new THREE.Matrix4().fromArray(this.facialTransformationMatrix.data);
                
                // Extract rotation as Euler angles
                const matrixRotation = new THREE.Euler().setFromRotationMatrix(matrix);
                
                // ENHANCED: Apply coordinate system corrections for your setup
                const targetRotation = {
                    x: matrixRotation.x,      // Pitch - inverted for correct direction
                    y: matrixRotation.y,       // Yaw - direct mapping
                    z: matrixRotation.z       // Roll - inverted for correct direction
                };
                
                // IMPROVED: Enhanced smoothing for matrix-based rotation
                const rotationSmoothing = 0.3; // Faster response since matrix data is more stable
                const rollSmoothing = 0.25;    // Even faster for roll since it's more direct
                
                this.smoothedRotation.x = this.smoothedRotation.x * (1 - rotationSmoothing) + 
                                        targetRotation.x * rotationSmoothing;
                this.smoothedRotation.y = this.smoothedRotation.y * (1 - rotationSmoothing) + 
                                        targetRotation.y * rotationSmoothing;
                this.smoothedRotation.z = this.smoothedRotation.z * (1 - rollSmoothing) + 
                                        targetRotation.z * rollSmoothing;
                
                this.headRotation = this.smoothedRotation;
                
                // KEEP your existing face position tracking
                this.updateFacePositionFromLandmarks();
                
            }

            updateFacePositionFromLandmarks() {
                if (this.faces.length === 0) return;
                
                const landmarks = this.faces[0];
                
                // KEEP your existing face center calculation
                const LEFT_EYE = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246];
                const RIGHT_EYE = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398];
                const NOSE_TIP = [1];
                
                const leftEyeCenter = this.getAveragePoint(landmarks, LEFT_EYE);
                const rightEyeCenter = this.getAveragePoint(landmarks, RIGHT_EYE);
                const noseTip = landmarks[NOSE_TIP[0]];
                
                if (leftEyeCenter && rightEyeCenter && noseTip) {
                    const eyeMidpoint = {
                        x: (leftEyeCenter.x + rightEyeCenter.x) / 2,
                        y: (leftEyeCenter.y + rightEyeCenter.y) / 2,
                        z: (leftEyeCenter.z + rightEyeCenter.z) / 2
                    };
                    
                    this.faceCenter = {
                        x: eyeMidpoint.x,
                        y: eyeMidpoint.y + 0.03,
                        z: (eyeMidpoint.z + noseTip.z) / 2
                    };
                    
                    // Calculate face scale
                    const eyeDistance = Math.sqrt(
                        Math.pow(rightEyeCenter.x - leftEyeCenter.x, 2) + 
                        Math.pow(rightEyeCenter.y - leftEyeCenter.y, 2)
                    );
                    this.calculateRealWorldScale(eyeDistance, this.faceCenter.z);
                }
                
                // KEEP your existing position smoothing
                const positionSmoothing = 0.8;
                this.smoothedPosition.x = this.smoothedPosition.x * (1 - positionSmoothing) + 
                                        this.faceCenter.x * positionSmoothing;
                this.smoothedPosition.y = this.smoothedPosition.y * (1 - positionSmoothing) + 
                                        this.faceCenter.y * positionSmoothing;
                this.smoothedPosition.z = this.smoothedPosition.z * (1 - positionSmoothing) + 
                                        this.faceCenter.z * positionSmoothing;
                
                const scaleSmoothing = 0.9;
                this.smoothedScale = this.smoothedScale * (1 - scaleSmoothing) + 
                                    this.realWorldFaceScale * scaleSmoothing;
            }
            
            // NEW: Initialize face lock system
            initializeFaceLock() {
                if (this.faces.length === 0) return;
                
                const landmarks = this.faces[0];
                const FACE_OVAL = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109];
                
                // Calculate initial face center for lock reference
                let centerX = 0, centerY = 0, centerZ = 0;
                let validPoints = 0;
                
                FACE_OVAL.forEach(idx => {
                    if (landmarks[idx]) {
                        centerX += landmarks[idx].x;
                        centerY += landmarks[idx].y;
                        centerZ += landmarks[idx].z;
                        validPoints++;
                    }
                });
                
                if (validPoints > 0) {
                    this.faceLockCenter = {
                        x: centerX / validPoints,
                        y: centerY / validPoints,
                        z: centerZ / validPoints
                    };
                    
                    // Initialize smoothed values to lock center
                    this.smoothedPosition = { ...this.faceLockCenter };
                    this.faceLockInitialized = true;
                    
                    console.log('Face lock initialized at:', this.faceLockCenter);
                }
            }

            // FIXED: Proper coordinate system handling
            updateFaceTrackingFromLandmarks() {
                if (this.faces.length === 0) return;
                
                const landmarks = this.faces[0];

                
                // FACE CENTER FIX: Calculate center using key facial features for proper positioning
                const FACE_OVAL = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109];
                const LEFT_EYE = [33, 7, 163, 144, 145, 153, 154, 155, 133, 173, 157, 158, 159, 160, 161, 246];
                const RIGHT_EYE = [362, 382, 381, 380, 374, 373, 390, 249, 263, 466, 388, 387, 386, 385, 384, 398];
                const NOSE_TIP = [1];
                const FOREHEAD = [10, 151];
                const CHIN = [175];
                
                // Calculate face center using eye line and nose for better positioning
                const leftEyeCenter = this.getAveragePoint(landmarks, LEFT_EYE);
                const rightEyeCenter = this.getAveragePoint(landmarks, RIGHT_EYE);
                const noseTip = landmarks[NOSE_TIP[0]];
                
                if (leftEyeCenter && rightEyeCenter && noseTip) {
                    // Use eye midpoint and nose tip to get better face center
                    const eyeMidpoint = {
                        x: (leftEyeCenter.x + rightEyeCenter.x) / 2,
                        y: (leftEyeCenter.y + rightEyeCenter.y) / 2,
                        z: (leftEyeCenter.z + rightEyeCenter.z) / 2
                    };
                    
                    // Face center should be slightly below eye line for natural positioning
                    this.faceCenter = {
                        x: eyeMidpoint.x,
                        y: eyeMidpoint.y + 0.03, // Slightly below eyes for better face coverage
                        z: (eyeMidpoint.z + noseTip.z) / 2 // Average depth
                    };
                } else {
                    // Fallback to face oval center
                    let centerX = 0, centerY = 0, centerZ = 0;
                    let validPoints = 0;
                    
                    FACE_OVAL.forEach(idx => {
                        if (landmarks[idx]) {
                            centerX += landmarks[idx].x;
                            centerY += landmarks[idx].y;
                            centerZ += landmarks[idx].z;
                            validPoints++;
                        }
                    });
                    
                    if (validPoints > 0) {
                        this.faceCenter = {
                            x: centerX / validPoints,
                            y: centerY / validPoints,
                            z: centerZ / validPoints
                        };
                    }
                }
                

                
                if (leftEyeCenter && rightEyeCenter) {
                    const eyeDistance = Math.sqrt(
                        Math.pow(rightEyeCenter.x - leftEyeCenter.x, 2) + 
                        Math.pow(rightEyeCenter.y - leftEyeCenter.y, 2)
                    );
                    
                    // REAL-WORLD SIZE CALIBRATION
                    // Calculate the real-world scale based on interpupillary distance
                    this.calculateRealWorldScale(eyeDistance, this.faceCenter.z);
                }
                
                // FIXED: Proper head rotation calculation
                if (landmarks[NOSE_TIP[0]] && leftEyeCenter && rightEyeCenter && landmarks[FOREHEAD[0]] && landmarks[CHIN[0]]) {
                    const noseTip = landmarks[NOSE_TIP[0]];
                    const forehead = landmarks[FOREHEAD[0]];
                    const chin = landmarks[CHIN[0]];
                    
                    const eyeMidpoint = {
                        x: (leftEyeCenter.x + rightEyeCenter.x) / 2,
                        y: (leftEyeCenter.y + rightEyeCenter.y) / 2,
                        z: (leftEyeCenter.z + rightEyeCenter.z) / 2
                    };
                    
                    // FIXED: Correct rotation calculations
                    // Roll (head tilt) - mirror corrected
                    const roll = -Math.atan2(rightEyeCenter.y - leftEyeCenter.y, rightEyeCenter.x - leftEyeCenter.x);
                    
                    // FIXED: Pitch (head up/down) - use proper Y coordinate difference
                    const pitch = Math.atan2(noseTip.y - eyeMidpoint.y, Math.abs(noseTip.z - eyeMidpoint.z) + 0.01) * 1.5;
                    
                    // FIXED: Yaw (head left/right) - mirror corrected and proper Z handling
                    const yaw = Math.atan2(noseTip.x - eyeMidpoint.x, Math.abs(noseTip.z - eyeMidpoint.z) + 0.01) * 1.5;
                    
                    const targetRotation = { x: pitch, y: yaw, z: roll };
                    
                    // Apply smoothing with appropriate factors
                    const rotationSmoothing = 0.4;
                    const rollSmoothing = 0.3; // Slightly faster response for head tilt

                    this.smoothedRotation.x = this.smoothedRotation.x * (1 - rotationSmoothing) + 
                                            targetRotation.x * rotationSmoothing;
                    this.smoothedRotation.y = this.smoothedRotation.y * (1 - rotationSmoothing) + 
                                            targetRotation.y * rotationSmoothing;
                    this.smoothedRotation.z = this.smoothedRotation.z * (1 - rollSmoothing) + 
                                            targetRotation.z * rollSmoothing; // Faster roll response

                    this.headRotation = this.smoothedRotation;
                }
                
                // FACE LOCK: Much stronger position smoothing to reduce floating
                const positionSmoothing = 0.8; // Increased from 0.6 for more stability
                this.smoothedPosition.x = this.smoothedPosition.x * (1 - positionSmoothing) + 
                                        this.faceCenter.x * positionSmoothing;
                this.smoothedPosition.y = this.smoothedPosition.y * (1 - positionSmoothing) + 
                                        this.faceCenter.y * positionSmoothing;
                this.smoothedPosition.z = this.smoothedPosition.z * (1 - positionSmoothing) + 
                                        this.faceCenter.z * positionSmoothing;
                
                // FACE LOCK: Stronger scale smoothing for stable attachment
                const scaleSmoothing = 0.7; // Increased smoothing for scale
                this.smoothedScale = this.smoothedScale * (1 - scaleSmoothing) + 
                                this.realWorldFaceScale * scaleSmoothing;
            }


            calculateRealWorldScale(eyeDistanceNormalized, faceDepthZ) {
                if (!this.baselineScale) {
                    this.baselineScale = eyeDistanceNormalized * 2.5;
                    this.baselineScale = Math.max(0.3, Math.min(0.8, this.baselineScale));
                }
                
                const currentScale = eyeDistanceNormalized * 2.5;
                const scaleRatio = currentScale / this.baselineScale;
                
                if (scaleRatio > 1.3 || scaleRatio < 0.7) {
                    this.realWorldFaceScale = Math.max(0.3, Math.min(0.8, currentScale));
                    this.baselineScale = this.realWorldFaceScale;
                } else {
                    this.realWorldFaceScale = this.baselineScale;
                }
            }


            // Helper method to calculate average point from landmark indices
            getAveragePoint(landmarks, indices) {
                let x = 0, y = 0, z = 0, count = 0;
                
                indices.forEach(idx => {
                    if (landmarks[idx]) {
                        x += landmarks[idx].x;
                        y += landmarks[idx].y;
                        z += landmarks[idx].z;
                        count++;
                    }
                });
                
                return count > 0 ? { x: x/count, y: y/count, z: z/count } : null;
            }
            

            calculateExpressionsFromBlendshapes() {
                if (this.faceBlendshapes.length === 0) return;
                
                const blendshapes = this.faceBlendshapes[0].categories;
                
                // IMPROVED: Direct mapping like in React code (more efficient)
                Object.keys(this.expressions).forEach(key => {
                    this.expressions[key] = 0;
                });
                
                // MORE EFFICIENT: Direct application without complex mapping
                blendshapes.forEach(blendshape => {
                    const categoryName = blendshape.categoryName;
                    let mappedName = null;
                    
                    // SIMPLIFIED mapping based on React code pattern
                    if (categoryName.includes('eyeBlink')) {
                        mappedName = categoryName.replace('eyeBlink', 'eyeBlink_').replace('Left', 'L').replace('Right', 'R');
                    } else if (categoryName.includes('mouthSmile')) {
                        mappedName = categoryName.replace('mouthSmile', 'mouthSmile_').replace('Left', 'L').replace('Right', 'R');
                    } else if (categoryName.includes('jaw')) {
                        mappedName = categoryName;
                    }
                    // Add more mappings as needed based on your morph target names
                    
                    if (mappedName && this.expressions.hasOwnProperty(mappedName)) {
                        let expressionValue = blendshape.score;
                        
                        // Apply smoothing directly
                        let smoothingFactor = 0.3;
                        if (categoryName.includes('eyeBlink')) {
                            smoothingFactor = 0.2;
                        }
                        
                        this.smoothedExpressions[mappedName] = 
                            this.smoothedExpressions[mappedName] * (1 - smoothingFactor) + 
                            expressionValue * smoothingFactor;
                    }
                });
            }

            renderFaceModel() {
                if (!this.faceModel || !this.renderer) return;
                
                // Clear previous render
                this.renderer.clear();
                
                // Remove previous models
                if (this.scene.getObjectByName('faceModel')) {
                    this.scene.remove(this.scene.getObjectByName('faceModel'));
                }
                if (this.scene.getObjectByName('blendingLayer')) {
                    this.scene.remove(this.scene.getObjectByName('blendingLayer'));
                }
                
                // PIVOT POINT SYSTEM: Create a pivot group for proper face-anchored rotation
                const pivotGroup = new THREE.Group();
                pivotGroup.name = 'facePivot';
                
                // Set pivot position to the face position
                const facePosition = this.convertToWorldCoords(this.smoothedPosition);
                pivotGroup.position.set(facePosition.x, facePosition.y, facePosition.z);
                
                // FIXED: Apply pitch and yaw to pivot group (for head turning)
                pivotGroup.rotation.set(
                    this.headRotation.x - Math.PI/4,     // Pitch
                    this.headRotation.y,                 // Yaw  
                    0                                    // No roll on pivot
                );
                
                // Clone the model and add it to pivot group
                const modelInstance = this.faceModel.clone();
                modelInstance.name = 'faceModel';
                
                // Position model at origin relative to pivot
                modelInstance.position.set(0, 0, 0);
                
                // FIXED: Apply roll (tilt) directly to the model
                modelInstance.rotation.set(
                    0,                                   // No additional pitch
                    0,                                   // No additional yaw
                    this.headRotation.z                  // Roll (head tilt)
                );
                
                // Apply scale to the model
                const finalScale = Math.max(0.2, Math.min(0.7, this.smoothedScale));
                modelInstance.scale.setScalar(finalScale);
                
                // Add model to pivot group
                pivotGroup.add(modelInstance);
                
                // ENHANCED: Add blending layer with same rotation system
                if (this.blendingLayer) {
                    const blendingInstance = this.blendingLayer.clone();
                    blendingInstance.name = 'blendingLayer';
                    
                    // Position blending layer at origin relative to pivot
                    blendingInstance.position.set(0, 0, 0);
                    
                    // Apply same roll rotation to blending layer
                    blendingInstance.rotation.set(
                        0,                               // No pitch
                        0,                               // No yaw
                        this.headRotation.z              // Same roll as main model
                    );
                    
                    blendingInstance.scale.setScalar(finalScale * 1.1);
                    
                    pivotGroup.add(blendingInstance);
                }
                
                // Apply morph target expressions (keep existing code)
                if (this.faceMeshObject && this.morphTargetNames.length > 0) {
                    const faceMesh = this.findFaceMesh(modelInstance);
                    if (faceMesh && faceMesh.morphTargetInfluences) {
                        this.morphTargetNames.forEach((name, index) => {
                            if (this.smoothedExpressions[name] !== undefined) {
                                faceMesh.morphTargetInfluences[index] = this.smoothedExpressions[name];
                            }
                        });
                    }
                }
                
                // Add the entire pivot group to scene
                this.scene.add(pivotGroup);
                
                // Render with proper layering
                this.renderer.render(this.scene, this.threeCamera);
                
                // Update sync info
                const activeExpressions = Object.values(this.smoothedExpressions).filter(v => v > 0.1).length;
                document.getElementById('syncInfo').textContent = 
                    `Scale: ${finalScale.toFixed(2)}, Active: ${activeExpressions}, Tilt: ${(this.headRotation.z * 180/Math.PI).toFixed(1)}°`;
            }

            
            findFaceMesh(object) {
                let faceMesh = null;
                object.traverse((child) => {
                    if (child.isMesh && child.morphTargetDictionary && Object.keys(child.morphTargetDictionary).length > 0) {
                        faceMesh = child;
                    }
                });
                return faceMesh;
            }
            
            updateExpressionDebug() {
                const activeExpressions = Object.entries(this.smoothedExpressions)
                    .filter(([name, value]) => value > 0.05)
                    .sort(([,a], [,b]) => b - a)
                    .slice(0, 15)
                    .map(([name, value]) => `${name}: ${value.toFixed(2)}`)
                    .join('<br>');
                
                const debugElement = document.getElementById('expressionValues');
                if (activeExpressions) {
                    debugElement.innerHTML = activeExpressions + 
                        `<br><br><strong>Position:</strong><br>X: ${this.smoothedPosition.x.toFixed(3)}<br>Y: ${this.smoothedPosition.y.toFixed(3)}<br>Z: ${this.smoothedPosition.z.toFixed(3)}` +
                        `<br><br><strong>Rotation:</strong><br>Pitch: ${(this.headRotation.x * 180/Math.PI).toFixed(1)}°<br>Yaw: ${(this.headRotation.y * 180/Math.PI).toFixed(1)}°<br>Roll: ${(this.headRotation.z * 180/Math.PI).toFixed(1)}°` +
                        `<br><br><strong>Scale:</strong> ${this.smoothedScale.toFixed(2)}`;
                } else {
                    debugElement.innerHTML = 'No active expressions';
                }
            }
            
            // FACE ATTACHMENT FIX: Precise face-locked coordinate conversion
            convertToWorldCoords(facePos) {
                
                // Direct coordinate mapping for perfect face lock
                const worldX = (facePos.x - 0.5) * 2.0;  // Convert 0-1 to -1 to 1
                const worldY = -(facePos.y - 0.5) * 2.0; // Flip Y and convert 0-1 to -1 to 1
                
                // Keep model exactly at face depth - no floating!
                const worldZ = 0.0; // Exactly at the screen plane
                
                return {
                    x: worldX,
                    y: worldY, 
                    z: worldZ
                };
            }
            
            clearScene() {
                this.hidePersistentModel();
            }
            
            startTracking() {
                console.log('Face tracking started with Face Landmarker');
            }
            
            setupResizeHandler() {
                window.addEventListener('resize', () => {
                    this.threeCamera.aspect = window.innerWidth / window.innerHeight;
                    this.threeCamera.updateProjectionMatrix();
                    this.renderer.setSize(window.innerWidth, window.innerHeight);
                    console.log('Resized to:', window.innerWidth, 'x', window.innerHeight);
                });
            }
            

            cleanup() {
                this.destroyPersistentModel();
                
                if (this.faceLandmarker) this.faceLandmarker.close();
                if (this.renderer) this.renderer.dispose();
                if (this.video.srcObject) {
                    this.video.srcObject.getTracks().forEach(track => track.stop());
                }
            }

        }
        
        // Global functions for buttons
        let tracker;
        
        window.loadBuiltInModel = async function() {
            if (!tracker) return;
            try {
                document.getElementById('modelStatus').textContent = 'Creating Built-in Model...';
                const gltf = await tracker.createBuiltInFaceModel();
                tracker.setupLoadedModel(gltf, 'Built-in Face Model');
            } catch (error) {
                console.error('Built-in model failed:', error);
                document.getElementById('modelStatus').textContent = 'Built-in Model Failed ❌';
            }
        };
        
        window.loadGLBModel = async function() {
            if (!tracker) return;
            try {
                const gltf = await tracker.loadGLBModelModern('face.glb');
                tracker.setupLoadedModel(gltf, 'GLB Model');
            } catch (error) {
                console.error('GLB loading failed:', error);
                document.getElementById('modelStatus').textContent = 'GLB Load Failed ❌';
                document.getElementById('modelStatus').style.color = '#ff6b6b';
            }
        };
        
        window.loadFromURL = function() {
            const url = prompt('Enter GLB/GLTF URL:');
            if (url && tracker) {
                tracker.loadGLBModelModern(url)
                    .then(gltf => tracker.setupLoadedModel(gltf, 'URL Model'))
                    .catch(error => {
                        console.error('URL loading failed:', error);
                        document.getElementById('modelStatus').textContent = 'URL Load Failed ❌';
                    });
            }
        };
        
        // Initialize the tracker
        window.addEventListener('load', async () => {
            try {
                tracker = new ModernFaceTracker();
            } catch (error) {
                console.error('Failed to initialize tracker:', error);
                document.getElementById('statusText').textContent = 'Failed: ' + error.message;
            }
        });
        
        window.addEventListener('beforeunload', () => {
            if (tracker) tracker.cleanup();
        });
        
        document.addEventListener('visibilitychange', () => {
            if (!tracker) return;
            
            if (document.hidden) {
                if (tracker.camera) tracker.camera.stop();
            } else {
                if (tracker.camera) tracker.camera.start();
            }
        });
    </script>
</body>
</html>